import os
import shutil
import hashlib
import logging
import argparse
from pathlib import Path
from datetime import datetime
from PIL import Image
import imagehash
import exifread
import sys
import concurrent.futures

# ===== é»˜è®¤é…ç½®ï¼ˆå¯è¢«å‚æ•°è¦†ç›–ï¼‰=====
HASH_ALGO = 'sha256'
HASH_THRESHOLD = 5
DEFAULT_LOG_FILE = "photo_dedup.log"  # ä¿ç•™é»˜è®¤æ–‡ä»¶å
IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp', '.mp4', '.avi', '.mov', '.mkv'] # æ·»åŠ å¸¸è§è§†é¢‘æ ¼å¼
DEFAULT_MIN_SIZE_KB = 100 # é»˜è®¤æœ€å°æ–‡ä»¶å¤§å°ä¸º 100 KB
GPS_THRESHOLD = 0.0001

# ===== å·¥å…·å‡½æ•° =====

def file_hash(filepath, algo=HASH_ALGO):
    h = hashlib.new(algo)
    with open(filepath, 'rb') as f:
        while chunk := f.read(8192):
            h.update(chunk)
    return h.hexdigest()

def to_decimal_degrees(dms):
    degrees = float(dms[0].num) / float(dms[0].den)
    minutes = float(dms[1].num) / float(dms[1].den)
    seconds = float(dms[2].num) / float(dms[2].den)
    return degrees + (minutes / 60.0) + (seconds / 3600.0)

def get_gps_coordinates(filepath):
    try:
        with open(filepath, 'rb') as f:
            tags = exifread.process_file(f, stop_tag="GPS GPSLatitude", details=False)
            if 'GPS GPSLatitude' in tags and 'GPS GPSLongitude' in tags:
                lat_val = tags['GPS GPSLatitude'].values
                lon_val = tags['GPS GPSLongitude'].values

                latitude = to_decimal_degrees(lat_val)
                longitude = to_decimal_degrees(lon_val)
                lat_ref = tags.get('GPS GPSLatitudeRef')
                lon_ref = tags.get('GPS GPSLongitudeRef')

                if lat_ref and lat_ref.values[0] == 'S':
                    latitude = -latitude
                if lon_ref and lon_ref.values[0] == 'W':
                    longitude = -longitude

                return latitude, longitude
        return None
    except Exception:
        return None

def compare_gps(coord1, coord2, threshold=GPS_THRESHOLD):
    if coord1 is None or coord2 is None:
        return False
    lat1, lon1 = coord1
    lat2, lon2 = coord2
    return abs(lat1 - lat2) < threshold and abs(lon1 - lon2) < threshold

def are_similar_images(file1, file2, threshold=HASH_THRESHOLD):
    try:
        hash1 = imagehash.phash(Image.open(file1).convert('RGB'))
        hash2 = imagehash.phash(Image.open(file2).convert('RGB'))
        return abs(hash1 - hash2) <= threshold
    except Exception:
        return False

def get_image_resolution(filepath):
    try:
        img = Image.open(filepath)
        return img.size[0] * img.size[1]
    except Exception:
        return 0

def backup_file(file_path, perform_actions, backup_dir, source_dir_arg, simple_backup=False, simple_backup_with_path=False, reason=""):
    original_name = file_path.stem.replace(" ", "_")
    ext = file_path.suffix.lower()
    timestamp_dir = backup_dir / datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d')
    timestamp_dir.mkdir(parents=True, exist_ok=True)

    if simple_backup_with_path:
        parts = file_path.parts
        relative_path_parts = parts[len(Path(source_dir_arg).parts):-1]
        recursive_backup_dir = timestamp_dir / Path(*relative_path_parts)
        recursive_backup_dir.mkdir(parents=True, exist_ok=True)
        backup_path = recursive_backup_dir / f"{original_name}{ext}"
    elif simple_backup:
        backup_path = timestamp_dir / f"{original_name}{ext}"
        if backup_path.exists():
            parts = file_path.parts
            relative_path_parts = parts[len(Path(source_dir_arg).parts):-1] # è·å–æºç›®å½•åçš„ç›¸å¯¹è·¯å¾„
            recursive_backup_dir = timestamp_dir / Path(*relative_path_parts)
            recursive_backup_dir.mkdir(parents=True, exist_ok=True)
            backup_path = recursive_backup_dir / f"{original_name}{ext}"
    else:
        file_hash_name = file_hash(file_path)
        suffix = f"_{reason}" if reason else ""
        new_file_name = f"{original_name}{suffix}_{file_hash_name}{ext}"
        backup_path = timestamp_dir / new_file_name
        if len(str(backup_path)) > 255 and hasattr(args, 'source_dir'): # å¤„ç†é•¿æ–‡ä»¶å
            source_path = Path(args.source_dir)
            parts = file_path.parts
            relative_path_parts = parts[len(source_path.parts):-1]
            recursive_backup_dir = timestamp_dir / Path(*relative_path_parts)
            recursive_backup_dir.mkdir(parents=True, exist_ok=True)
            backup_path = recursive_backup_dir / new_file_name

    backup_path.parent.mkdir(parents=True, exist_ok=True)

    if backup_path.exists():
        logging.info(f"å¤‡ä»½æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {backup_path}")
        return

    if perform_actions:
        shutil.copy2(file_path, backup_path)
    logging.info(f"{'[æ‰§è¡Œ] ' if perform_actions else '[æ¨¡æ‹Ÿ] '}å·²å¤‡ä»½: {file_path} â†’ {backup_path}")

def is_image_file(filepath):
    try:
        Image.open(filepath).verify()
        return True
    except Exception:
        return False

def log_message(message, enable_console_log, is_executing):
    log_prefix = "[æ‰§è¡Œ] " if is_executing else "[æ¨¡æ‹Ÿ] "
    logging.info(log_prefix + message)
    if enable_console_log:
        print(log_prefix + message)

def safe_delete_file(file_path, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, is_executing, source_dir_arg, simple_backup=False, simple_backup_with_path=False, reason=""):
    if not perform_actions:
        log_message(f"[åˆ é™¤]: {file_path}", enable_console_log, is_executing)
        return

    if delete_soft and trash_dir:
        trash_path = Path(trash_dir) / file_path.name
        trash_path.parent.mkdir(parents=True, exist_ok=True)
        backup_file(file_path, perform_actions, backup_dir, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason=f"backup_before_soft_delete_{reason}")
        try:
            shutil.move(str(file_path), str(trash_path))
            log_message(f"[è½¯åˆ é™¤] å·²ç§»åŠ¨åˆ° {trash_path}: {file_path}", enable_console_log, is_executing)
        except Exception as e:
            logging.error(f"âŒ [è½¯åˆ é™¤] ç§»åŠ¨æ–‡ä»¶å¤±è´¥ {file_path} åˆ° {trash_path}: {e}")
    else: # é»˜è®¤è¡Œä¸ºä»ç„¶æ˜¯å¤‡ä»½ååˆ é™¤
        backup_file(file_path, perform_actions, backup_dir, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason=reason)
        try:
            file_path.unlink()
            log_message(f"[åˆ é™¤] (å¤‡ä»½å·²å®Œæˆ): {file_path}", enable_console_log, is_executing)
        except Exception as e:
            logging.error(f"âŒ åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

def calculate_phash(filepath, cache):
    if filepath not in cache:
        try:
            cache[filepath] = imagehash.phash(Image.open(filepath).convert('RGB'))
        except Exception as e:
            logging.warning(f"\tæ„ŸçŸ¥å“ˆå¸Œè®¡ç®—å¤±è´¥: {filepath}ï¼ŒåŸå› : {e}")
            return None
    return cache[filepath]

def handle_exact_duplicate(file, original, args, source_dir_arg):
    gps_file = get_gps_coordinates(file)
    gps_original = get_gps_coordinates(original)
    perform_actions = args.d
    backup_dir = Path(args.backup_dir)
    delete_soft = args.delete_soft
    trash_dir = Path(args.trash_dir) if args.trash_dir else None
    enable_console_log = args.log
    simple_backup = args.simple_backup
    simple_backup_with_path = args.s1

    if gps_file is not None and gps_original is None:
        safe_delete_file(original, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="gps")
        log_message(f"ä¿ç•™å«GPS: {file}, åˆ é™¤: {original}", enable_console_log, perform_actions)
        return 1, 1
    elif gps_file is None and gps_original is not None:
        safe_delete_file(file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="gps")
        log_message(f"ä¿ç•™å«GPS: {original}, åˆ é™¤: {file}", enable_console_log, perform_actions)
        return 1, 0
    elif gps_file is not None and gps_original is not None and compare_gps(gps_file, gps_original):
        safe_delete_file(file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="duplicate")
        log_message(f"ä¿ç•™: {original}, åˆ é™¤: {file}", enable_console_log, perform_actions)
        return 1, 0
    else:
        safe_delete_file(file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="duplicate") # å¦‚æœ GPS ä¿¡æ¯å·®å¼‚è¿‡å¤§ï¼Œæš‚æ—¶è§†ä¸ºé‡å¤æ–‡ä»¶
        log_message(f"ä¿ç•™: {original}, åˆ é™¤: {file} (GPSä½ç½®å¯èƒ½ä¸åŒ)", enable_console_log, perform_actions)
        return 1, 0

def handle_new_file(file, seen_hashes, phash_cache, phash_list, args, source_dir_arg):
    is_duplicate = False
    perform_actions = args.d
    backup_dir = Path(args.backup_dir)
    delete_soft = args.delete_soft
    trash_dir = Path(args.trash_dir) if args.trash_dir else None
    enable_console_log = args.log
    simple_backup = args.simple_backup
    simple_backup_with_path = args.s1
    hash_threshold = args.hash_threshold
    prefer_resolution = args.prefer_resolution

    if args.include_similar:
        file_phash = calculate_phash(file, phash_cache)
        if file_phash is not None:
            for original_file, original_phash in list(phash_list): # ä½¿ç”¨ list è¿›è¡Œå®‰å…¨è¿­ä»£
                if original_phash is not None and abs(file_phash - original_phash) <= hash_threshold:
                    gps_file = get_gps_coordinates(file)
                    gps_orig = get_gps_coordinates(original_file)

                    if gps_file and not gps_orig:
                        safe_delete_file(original_file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="gps")
                        log_message(f"[ç›¸ä¼¼] ä¿ç•™å«GPS: {file}, åˆ é™¤: {original_file}", enable_console_log, perform_actions)
                        phash_list[:] = [(f, h) for f, h in phash_list if f != original_file]
                        phash_list.append((file, file_phash))
                        return 1, 1
                    elif not gps_file and gps_orig:
                        safe_delete_file(file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="gps")
                        log_message(f"[ç›¸ä¼¼] ä¿ç•™å«GPS: {original_file}, åˆ é™¤: {file}", enable_console_log, perform_actions)
                        return 1, 0
                    else:
                        if prefer_resolution:
                            res_file = get_image_resolution(file)
                            res_orig = get_image_resolution(original_file)
                            if res_file > res_orig:
                                safe_delete_file(original_file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="resolution")
                                log_message(f"[ç›¸ä¼¼] ä¿ç•™åˆ†è¾¨ç‡æ›´é«˜: {file}, åˆ é™¤: {original_file}", enable_console_log, perform_actions)
                                phash_list[:] = [(f, h) for f, h in phash_list if f != original_file]
                                phash_list.append((file, file_phash))
                                return 1, 1
                            elif res_file < res_orig:
                                safe_delete_file(file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="resolution")
                                log_message(f"[ç›¸ä¼¼] ä¿ç•™: {original_file} (åˆ†è¾¨ç‡æ›´é«˜), åˆ é™¤: {file}", enable_console_log, perform_actions)
                                return 1, 0
                            else: # å¦‚æœåˆ†è¾¨ç‡ç›¸åŒï¼Œåˆ™æ¯”è¾ƒæ–‡ä»¶å¤§å°
                                if file.stat().st_size > original_file.stat().st_size:
                                    safe_delete_file(original_file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="larger")
                                    log_message(f"[ç›¸ä¼¼] ä¿ç•™æ–‡ä»¶è¾ƒå¤§: {file}, åˆ é™¤: {original_file}", enable_console_log, perform_actions)
                                    phash_list[:] = [(f, h) for f, h in phash_list if f != original_file]
                                    phash_list.append((file, file_phash))
                                    return 1, 1
                                else:
                                    safe_delete_file(file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="larger")
                                    log_message(f"[ç›¸ä¼¼] ä¿ç•™: {original_file} (æ–‡ä»¶è¾ƒå¤§), åˆ é™¤: {file}", enable_console_log, perform_actions)
                                    return 1, 0
                        else: # å¦‚æœä¸ä¼˜å…ˆè€ƒè™‘åˆ†è¾¨ç‡ï¼Œåˆ™æ¯”è¾ƒæ–‡ä»¶å¤§å°
                            if file.stat().st_size > original_file.stat().st_size:
                                safe_delete_file(original_file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="larger")
                                log_message(f"[ç›¸ä¼¼] ä¿ç•™æ–‡ä»¶è¾ƒå¤§: {file}, åˆ é™¤: {original_file}", enable_console_log, perform_actions)
                                phash_list[:] = [(f, h) for f, h in phash_list if f != original_file]
                                phash_list.append((file, file_phash))
                                return 1, 1
                            else:
                                safe_delete_file(file, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, perform_actions, source_dir_arg, simple_backup=simple_backup, simple_backup_with_path=simple_backup_with_path, reason="larger")
                                log_message(f"[ç›¸ä¼¼] ä¿ç•™: {original_file} (æ–‡ä»¶è¾ƒå¤§), åˆ é™¤: {file}", enable_console_log, perform_actions)
                                return 1, 0
                    is_duplicate = True
                    break
            if not is_duplicate and file_phash is not None:
                phash_list.append((file, file_phash))

    if not is_duplicate:
        seen_hashes[content_hash] = file
        return 0, 1 # å·²åˆ é™¤, å·²ä¿ç•™

    return 0, 0 # ä¸åº”è¯¥æ‰§è¡Œåˆ°è¿™é‡Œ

def process_directory(perform_actions, source_dir, backup_dir, include_similar, enable_console_log, delete_soft, trash_dir, num_threads, min_size_bytes, simple_backup, simple_backup_with_path):
    seen_hashes = {}
    phash_cache = {}
    phash_list = []
    files = [f for f in source_dir.rglob('*')
             if f.is_file() and
                 os.access(f, os.W_OK) and
                 not f.name.lower().endswith(('.tmp', '.db')) and
                 f.suffix.lower() in IMAGE_EXTENSIONS and
                 f.stat().st_size >= min_size_bytes
             ]
    scanned_count = len(files)
    deleted_count = 0
    retained_count = 0

    print(f"\tğŸ” å¼€å§‹æ‰«æç›®å½•: {source_dir}, å…±æ‰¾åˆ° {scanned_count} ä¸ªæ–‡ä»¶ (æœ€å°å¤§å°: {min_size_bytes // 1024} KB), åŒ…æ‹¬è§†é¢‘: True") # ç®€åŒ–å¤„ç†ï¼Œé»˜è®¤åŒ…å«è§†é¢‘

    if include_similar:
        print("\tğŸ¨ é¢„å…ˆè®¡ç®—æ„ŸçŸ¥å“ˆå¸Œ...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(calculate_phash, file, phash_cache) for file in files]
            for i, future in enumerate(concurrent.futures.as_completed(futures)):
                progress = (i + 1) / scanned_count * 100
                print(f"\t\rğŸ“ æ„ŸçŸ¥å“ˆå¸Œè®¡ç®—è¿›åº¦: {progress:.2f}% ({i + 1}/{scanned_count})", end="")
        print("\n\tâœ… æ„ŸçŸ¥å“ˆå¸Œè®¡ç®—å®Œæˆ.")

    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = [executor.submit(process_file, file, seen_hashes, phash_cache, phash_list, perform_actions, backup_dir, delete_soft, trash_dir, enable_console_log, source_dir, min_size_bytes, simple_backup, simple_backup_with_path) for i, file in enumerate(files)]
        for i, future in enumerate(concurrent.futures.as_completed(futures)):
            deleted, retained = future.result()
            deleted_count += deleted
            retained_count += retained
            progress = (i + 1) / scanned_count * 100
            print(f"\t\rğŸ“ å¤„ç†è¿›åº¦: {progress:.2f}% ({i + 1}/{scanned_count}), å·²åˆ é™¤: {deleted_count}, å·²ä¿ç•™: {retained_count}", end="")

    print("\n\tâœ… æ‰«æå®Œæˆ")
    return scanned_count, retained_count, deleted_count

# ===== ä¸»ç¨‹åºå…¥å£ =====
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="\tæ¸…ç†é‡å¤ç…§ç‰‡å’Œè§†é¢‘ï¼Œä¼˜å…ˆä¿ç•™å«GPSä¿¡æ¯çš„æ–‡ä»¶ (é»˜è®¤æ¨¡æ‹Ÿæ‰§è¡Œ)")
    parser.add_argument("source_dir", nargs='?', type=str, help="\tè¦å¤„ç†çš„å›¾ç‰‡å’Œè§†é¢‘ç›®å½• (ç•™ç©ºåˆ™æç¤ºè¾“å…¥)")
    parser.add_argument("--optional-source-dir", nargs='?', type=str, help="\tå¯é€‰çš„ç¬¬äºŒä¸ªå›¾ç‰‡å’Œè§†é¢‘ç›®å½•")
    parser.add_argument("backup_dir", nargs='?', type=str, help="\tè¢«åˆ é™¤æ–‡ä»¶çš„å¤‡ä»½ç›®å½• (ç•™ç©ºåˆ™æç¤ºè¾“å…¥)")
    parser.add_argument("-d", action="store_true", help="\tæ‰§è¡Œå®é™…çš„åˆ é™¤å’Œå¤‡ä»½æ“ä½œ")
    parser.add_argument("--include-similar", action="store_true", help="\tå¯ç”¨æ„ŸçŸ¥å“ˆå¸Œæ¯”å¯¹ï¼Œåˆ é™¤ç›¸ä¼¼å›¾ç‰‡")
    parser.add_argument("-log", action="store_true", help="\tå°†æ—¥å¿—åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°")
    parser.add_argument("--delete-soft", action="store_true", help="\tå¯ç”¨è½¯åˆ é™¤ï¼ˆç§»åŠ¨åˆ°æŒ‡å®šç›®å½•ï¼‰")
    parser.add_argument("--trash-dir", nargs='?', type=str, help="\tæŒ‡å®šè½¯åˆ é™¤ç›®å½• (ç•™ç©ºåˆ™æç¤ºè¾“å…¥)")
    parser.add_argument("--log-dir", nargs='?', type=str, help="\tæŒ‡å®šæ—¥å¿—æ–‡ä»¶è¾“å‡ºç›®å½• (ç•™ç©ºåˆ™æç¤ºè¾“å…¥)")
    parser.add_argument("--hash-threshold", type=int, default=HASH_THRESHOLD, help=f"\tç›¸ä¼¼å›¾ç‰‡å“ˆå¸Œå€¼é˜ˆå€¼ (é»˜è®¤: {HASH_THRESHOLD})")
    parser.add_argument("--threads", type=int, default=4, help="\tè®¾ç½®å¤„ç†çº¿ç¨‹æ•° (é»˜è®¤: 4)") # æ·»åŠ çº¿ç¨‹æ•°å‚æ•°
    parser.add_argument("--prefer-resolution", action="store_true", help="\tå¯¹äºç›¸ä¼¼å›¾ç‰‡ï¼Œä¼˜å…ˆä¿ç•™åˆ†è¾¨ç‡æ›´é«˜çš„ç‰ˆæœ¬")
    parser.add_argument("-m", type=int, default=DEFAULT_MIN_SIZE_KB, help=f"\tè®¾ç½®æœ€å°æ‰«ææ–‡ä»¶å¤§å° (KB, é»˜è®¤: {DEFAULT_MIN_SIZE_KB} KB)") # æ·»åŠ æœ€å°æ–‡ä»¶å¤§å°å‚æ•°
    parser.add_argument("-v", "--include-videos", action="store_true", help="\tåŒ…å«è§†é¢‘æ–‡ä»¶è¿›è¡Œæ£€æµ‹ (æ”¯æŒ .mp4, .avi, .mov, .mkv)") # æ·»åŠ åŒ…å«è§†é¢‘æ–‡ä»¶å‚æ•°
    parser.add_argument("-s", "--simple-backup", action="store_true", help="\tå¯ç”¨ç®€å•å¤‡ä»½æ¨¡å¼ï¼šä»…ä¿ç•™åŸå§‹æ–‡ä»¶åï¼Œç›¸åŒæ–‡ä»¶åæ—¶æŒ‰æºæ–‡ä»¶è·¯å¾„å¤‡ä»½") # æ·»åŠ ç®€å•å¤‡ä»½æ¨¡å¼å‚æ•°
    parser.add_argument("-s1", action="store_true", help="\tå¯ç”¨å¤‡ä»½æ¨¡å¼ï¼šåŸå§‹è·¯å¾„+åŸå§‹æ–‡ä»¶å+åç¼€å") # æ–°å¢çš„å¤‡ä»½æ¨¡å¼å‚æ•°
    args = parser.parse_args()

    source_directories = []

    if not args.source_dir:
        args.source_dir = input("\n\tè¯·è¾“å…¥è¦å¤„ç†çš„ç¬¬ä¸€ä¸ªå›¾ç‰‡å’Œè§†é¢‘ç›®å½•: ")
    source_directory_1 = Path(args.source_dir)
    source_directories.append(source_directory_1)

    if args.optional_source_dir:
        source_directory_2 = Path(args.optional_source_dir)
        source_directories.append(source_directory_2)

    if not args.backup_dir:
        args.backup_dir = input("\tè¯·è¾“å…¥è¢«åˆ é™¤æ–‡ä»¶çš„å¤‡ä»½ç›®å½•: ")
    backup_directory = Path(args.backup_dir)

    perform_actions = args.d
    include_similar = args.include_similar
    enable_console_log = args.log
    delete_soft = args.delete_soft
    num_threads = args.threads
    prefer_resolution = args.prefer_resolution
    min_size_kb = args.m
    min_size_bytes = min_size_kb * 1024
    include_videos = args.include_videos
    simple_backup = args.simple_backup
    simple_backup_with_path = args.s1 # è·å–æ–°çš„å¤‡ä»½æ¨¡å¼å‚æ•°

    if include_videos:
        print("\tâš ï¸\u00A0 è§†é¢‘æ–‡ä»¶çš„ç›¸ä¼¼æ€§æ£€æµ‹ç›®å‰ä»…åŸºäºæ–‡ä»¶å“ˆå¸Œï¼Œä¸è¿›è¡Œå†…å®¹åˆ†æã€‚")
    if simple_backup:
        print("\tâ„¹ï¸\u00A0 å¯ç”¨ç®€å•å¤‡ä»½æ¨¡å¼ã€‚")
    if simple_backup_with_path:
        print("\tâ„¹ï¸\u00A0 å¯ç”¨å¤‡ä»½æ¨¡å¼ï¼šåŸå§‹è·¯å¾„+åŸå§‹æ–‡ä»¶å+åç¼€åã€‚")

    trash_dir = args.trash_dir
    if delete_soft and not trash_dir:
        trash_dir = input("\tè¯·è¾“å…¥è½¯åˆ é™¤ç›®å½•: ")
    trash_directory = Path(trash_dir) if trash_dir else None

    log_dir = args.log_dir
    if log_dir:
        log_file_path = Path(log_dir) / DEFAULT_LOG_FILE
    else:
        log_file_path = backup_directory / DEFAULT_LOG_FILE
        if not perform_actions: # å¦‚æœæ˜¯æ¨¡æ‹Ÿè¿è¡Œï¼Œæç¤ºç”¨æˆ·
            print(f"\t[æ¨¡æ‹Ÿ] æ—¥å¿—æ–‡ä»¶å°†ä¿å­˜åˆ°å¤‡ä»½ç›®å½•ä¸‹: {log_file_path}")
        else:
            print(f"\tæ—¥å¿—æ–‡ä»¶å°†ä¿å­˜åˆ°å¤‡ä»½ç›®å½•ä¸‹: {log_file_path}")

    logging.basicConfig(filename=str(log_file_path), level=logging.INFO,
                        format='%(asctime)s - %(levelname)s - %(message)s')

    print(f"\tè¿è¡Œæ¨¡å¼: {'æ‰§è¡Œ' if perform_actions else 'æ¨¡æ‹Ÿ'}")
    print(f"\tåŒ…å«ç›¸ä¼¼å›¾ç‰‡: {include_similar}")
    print(f"\tç›¸ä¼¼åº¦å“ˆå¸Œé˜ˆå€¼: {args.hash_threshold}")
    print(f"\tä½¿ç”¨çº¿ç¨‹æ•°: {num_threads}")
    print(f"\tä¼˜å…ˆä¿ç•™é«˜åˆ†è¾¨ç‡: {prefer_resolution}")
    print(f"\tæœ€å°æ‰«ææ–‡ä»¶å¤§å°: {min_size_kb} KB")
    print(f"\tåŒæ—¶è¾“å‡ºæ—¥å¿—åˆ°æ§åˆ¶å°: {enable_console_log}")
    print(f"\tåŒ…å«è§†é¢‘æ–‡ä»¶: {include_videos}")
    print(f"\tç®€å•å¤‡ä»½æ¨¡å¼(-s): {simple_backup}")
    print(f"\tåŸå§‹è·¯å¾„å¤‡ä»½æ¨¡å¼(-s1): {simple_backup_with_path}")
    print(f"\tè½¯åˆ é™¤: {delete_soft}")
    if delete_soft:
        print(f"\tå›æ”¶ç«™ç›®å½•: {trash_directory}")

    all_scanned_count = 0
    all_retained_count = 0
    all_deleted_count = 0

    for source_dir in source_directories:
        if source_dir.exists() and backup_directory.exists():
            scanned_count, retained_count, deleted_count = process_directory(
                perform_actions=perform_actions,
                source_dir=source_dir,
                backup_dir=backup_directory,
                include_similar=include_similar,
                enable_console_log=enable_console_log,
                delete_soft=delete_soft,
                trash_dir=trash_directory,
                num_threads=num_threads,
                min_size_bytes=min_size_bytes,
                simple_backup=simple_backup,
                simple_backup_with_path=simple_backup_with_path
            )
            all_scanned_count += scanned_count
            all_retained_count += retained_count
            all_deleted_count += deleted_count
        else:
            logging.error(f"\tâŒ ç›®å½•ä¸å­˜åœ¨: {source_dir} æˆ– {backup_directory}")
            print(f"\tâŒ é”™è¯¯: è¯·æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ - {source_dir} æˆ– {backup_directory}")

    print(f"\tâœ… æ‰«æå®Œæˆï¼Œå…±æ‰«æ {all_scanned_count} ä¸ªæ–‡ä»¶ï¼Œä¿ç•™ {all_retained_count} ä¸ªæ–‡ä»¶ï¼Œåˆ é™¤ {all_deleted_count} ä¸ªæ–‡ä»¶\n")
